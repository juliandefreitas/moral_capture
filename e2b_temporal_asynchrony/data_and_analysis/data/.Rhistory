if (!require(ggplot2)) {install.packages("ggplot2"); require(ggplot2)}
if (!require(ltm)) {install.packages("ltm"); require(ltm)}
if (!require(heplots)) {install.packages("heplots"); require(heplots)}
if (!require(lmtest)) {install.packages("lmtest"); require(lmtest)}
if (!require(lsr)) {install.packages("lsr"); require(lsr)}
if (!require(compute.es)) {install.packages("compute.es"); require(compute.es)}
if (!require(xlsx)) {install.packages("xlsx"); require(xlsx)}
if (!require(openxlsx)) {install.packages("openxlsx"); require(openxlsx)}
dir <- setwd("/Users/Julian/Dropbox (alvarezlab)/Research-DeFreitas/Projects/moralCapture/moralCapture_data_github/e1_illusory_wrongs/data_and_analysis/data_all_except_async")
files <- list.files(pattern=('*txt'))
myJSON <- lapply(files, function(x) fromJSON(file=x)) #join into one single JSON file
(data <- lapply(myJSON, function(myJSON) { as.data.frame(myJSON) }))
first_data <- (data <- do.call(rbind, data))
dir <- setwd("/Users/Julian/Dropbox (alvarezlab)/Research-DeFreitas/Projects/moralCapture/moralCapture_data_github/e1_illusory_wrongs/data_and_analysis/data_async")
files <- list.files(pattern=('*txt'))
myJSON <- lapply(files, function(x) fromJSON(file=x)) #join into one single JSON file
(data <- lapply(myJSON, function(myJSON) { as.data.frame(myJSON) }))
second_data <- (data <- do.call(rbind, data))
second_data$trialStruct.cond <- 3
#bind data into single dataset
data <- rbind(first_data,second_data)
#num ss recruited
dim(data) #562
#data after comprehension & timing
data <-subset(data,(data$trialStruct.comprehension == "E"))
dim(data)
3936+25
3936-25
data <-subset(data,((data$trialStruct.cond != 1 & data$trialStruct.displayTime < 4225 & data$trialStruct.displayTime > 4175) |
(data$trialStruct.cond == 1 & data$trialStruct.displayTime < 3961 & data$trialStruct.displayTime > 3911)))
dim(data) #490
562-490 #72 excluded
#demographics
sex <- as.factor(data$trialStruct.sex)
table(sex)[1]/sum(table(sex))
age <- as.numeric(levels(data$trialStruct.age))[data$trialStruct.age]
mean(age)
#data after whichCarExclusions
data <- subset(data, (data$trialStruct.whichCar_choice == 2))
dim(data) #397
#proportion passed which car q
100 - (((490-397)/490)*100)
## assign variable names
cond <- as.factor(data$trialStruct.cond)
blame <- as.numeric(levels(data$trialStruct.blame_scaled))[data$trialStruct.blame_scaled]
blame_choice <- as.factor(data$trialStruct.blame_choice)
whichCar <- as.factor(data$trialStruct.whichCar_choice)
whichCar <- as.factor(data$trialStruct.whichCar_choice)
length(whichCar[whichCar==2])
descrip <- data$trialStruct.description
descrip
## set up table for plotting
alpha = .05;
blame_mat <- matrix(NA,4,5)
colnames(blame_mat) <- c('cond','mean','sd','n','sem')
for (i in 1:4) {
blame_mat[i,] <- c(i,mean(blame[cond == i]),sd(blame[cond==i]), length(blame[cond == i]),0)
blame_mat[i,5] <- blame_mat[i,3]/sqrt(blame_mat[i,4])
}
blame.summary <- as.data.frame(blame_mat, stringsAsFactors=F)
condNames <- c('Launching','Launching Context', 'Offset Context', 'No Context')
group.colors <- c("1" = "#808080", "2" = "#236B8E", "3" = "#0680f9", "4" = "#0680f9")
## bar plot - blame scaled
title <- c('Blame Judgments')
p1<-ggplot(blame.summary[1:4,],aes(x=factor(cond),y=mean,fill=factor(cond))) +
scale_fill_manual(values=group.colors) +
stat_summary(fun.y=mean,position=position_dodge(),geom="bar")+theme_bw()+coord_cartesian(ylim=c(1, 8))
p1+geom_errorbar(aes(ymax=mean+sem, ymin=mean-sem), position="dodge")+ggtitle(title)+
scale_x_discrete(breaks = 1:length(condNames), labels=condNames)+
theme(panel.grid.major = element_blank(),legend.position="none", panel.grid.minor = element_blank(), axis.title.y=element_blank())+
theme(text = element_text(size=20), axis.text.x = element_text(angle = 45, hjust=1))+
xlab("Condition")+ylab("Mean")
## bar plot - blame mcq
blameTable <- matrix(NA,4)
blameTable[1] <- length(blame_choice[cond==1 & blame_choice==1])/length(blame_choice[cond==1])
blameTable[2] <- length(blame_choice[cond==2 & blame_choice==1])/length(blame_choice[cond==2])
blameTable[3] <- length(blame_choice[cond==3 & blame_choice==1])/length(blame_choice[cond==3])
blameTable[4] <- length(blame_choice[cond==4 & blame_choice==1])/length(blame_choice[cond==4])
condNames_bar <- c('Launching',' Launching Context', 'Offset Context', 'No Context')
barplot(blameTable[1:4], beside=TRUE,ylim=c(0,1.0), col=group.colors,
legend.text=TRUE, main="Proportion Blaming Driver of Red Car", cex.axis=1.0, cex.main = 1.5,names = condNames_bar,ylab="Proportion")
title <- c('Blame Judgments')
p1<-ggplot(blame.summary[1:4,],aes(x=factor(cond),y=mean,fill=factor(cond))) +
scale_fill_manual(values=group.colors) +
stat_summary(fun.y=mean,position=position_dodge(),geom="bar")+theme_bw()+coord_cartesian(ylim=c(1, 8))
p1+geom_errorbar(aes(ymax=mean+sem, ymin=mean-sem), position="dodge")+ggtitle(title)+
scale_x_discrete(breaks = 1:length(condNames), labels=condNames)+
theme(panel.grid.major = element_blank(),legend.position="none", panel.grid.minor = element_blank(), axis.title.y=element_blank())+
theme(text = element_text(size=20), axis.text.x = element_text(angle = 45, hjust=1))+
xlab("Condition")+ylab("Mean")
## anova
model <- aov(blame ~ cond)
summary(model)
etaSquared(model)
#means and sds
blame.summary
# launching v launching context
t.test(blame[cond==1 | cond==2] ~ cond[cond==1 | cond==2], var.equal=TRUE, paired=FALSE)
tes(2.263,124,108) #0.3
#means and sds
blame.summary
# launching context v no context
t.test(blame[cond==2 | cond==4] ~ cond[cond==2 | cond==4], var.equal=TRUE, paired=FALSE)
# launching context v no context
t.test(blame[cond==2 | cond==4] ~ cond[cond==2 | cond==4], var.equal=TRUE, paired=FALSE)
tes(4.1112,108,91) #0.6
# launching context v no context
t.test(blame[cond==2 | cond==4] ~ cond[cond==2 | cond==4], var.equal=TRUE, paired=FALSE)
tes(4.1112,108,91) #0.6
# launching context v asynchronous context
t.test(blame[cond==2 | cond==3] ~ cond[cond==2 | cond==3], var.equal=TRUE, paired=FALSE)
tes(4.0009,108,74) #0.6
# launching context v asynchronous context
t.test(blame[cond==2 | cond==3] ~ cond[cond==2 | cond==3], var.equal=TRUE, paired=FALSE)
tes(4.0009,108,74) #0.6
blameChoiceTable <- table(blame_choice,cond); blameChoiceTable
#proportions
blameTable
# launching v launching context
length(cond[cond == 1 | cond == 2])
chisq.test(cond[cond == 1 | cond == 2], blame_choice[cond==1 | cond == 2])
cramersV(blameChoiceTable[,1:2])
# launching context v no context
length(cond[cond == 2 | cond == 4])
chisq.test(cond[cond == 2 | cond == 4], blame_choice[cond==2 | cond == 4])
cramersV(blameChoiceTable[,c(2,4)])
# launching context v asynchronous context
length(cond[cond == 2 | cond == 3])
chisq.test(cond[cond == 2 | cond == 3], blame_choice[cond==2 | cond == 3])
cramersV(blameChoiceTable[,c(2,3)])
## clear workspace
rm(list = ls())
## necessary libraries
if (!require(psych)) {install.packages("psych"); require(psych)}
if (!require(fmsb)) {install.packages("fmsb"); require(fmsb)}
if (!require(compute.es)) {install.packages("compute.es"); require(compute.es)}
dir <- setwd("/Users/Julian/Dropbox (alvarezlab)/Research-DeFreitas/Projects/moralCapture/moralCapture_data_github/e1_illusory_wrongs/description_coding")
data <- read.csv('descriptions_e1_COMBINED.csv')
data <- read.csv('e1_coded_descriptions.csv')
labels(data)
pt_causal_codes <- data$pt_causal_code
jdf_causal_codes <- data$jdf_causal_code
causal_agreement <- data$causal_agreement
pt_realistic_codes <- data$pt_realistic_code
jdf_realistic_codes <- data$jdf_realistic_code
realistic_agreement <- data$realistic_agreement
#agreement between raters (cohen's kappa)
Kappa.test(pt_causal_codes, jdf_causal_codes)
#number of sentences where raters agreed
causal <- data$CAUSAL[causal_agreement == 1]
blame <- data$blame_scaled[causal_agreement == 1]
length(causal) #375
#proportion of sentences rated causal
length(causal[causal == 1])/length(causal)
#proportion of sentences rated causal
length(causal[causal == 1])/length(causal)
#t-test: causal vs. non-causal sentence on average blame
tapply(blame, causal, mean)
tapply(blame, causal, sd)
tapply(blame, causal, length)
t.test(blame ~ causal, var.equal=TRUE, paired=FALSE)
tes(-25.173,111,264) #2.29
t.test(blame ~ causal, var.equal=TRUE, paired=FALSE)
tes(-25.173,111,264) #2.29
#agreement between raters (cohen's kappa)
Kappa.test(pt_realistic_codes, jdf_realistic_codes) #1.00
#proportion that were unrealistic
realistic <- data$REALISTIC[realistic_agreement == 1]
blame <- data$blame_scaled[realistic_agreement == 1]
length(realistic[realistic == 0])/length(realistic)
length(realistic[realistic == 0])/length(realistic)*100
#proportion of sentences rated causal
length(causal[causal == 1])/length(causal)
#proportion of sentences rated causal
length(causal[causal == 1])/length(causal)
(length(realistic[realistic == 0])/length(realistic))*100
length(realistic[realistic == 0])/length(realistic)
## clear workspace
rm(list = ls())
## necessary libraries
if (!require(rjson)) {install.packages("rjson"); require(rjson)}
if (!require(ggplot2)) {install.packages("ggplot2"); require(ggplot2)}
if (!require(ltm)) {install.packages("ltm"); require(ltm)}
if (!require(heplots)) {install.packages("heplots"); require(heplots)}
if (!require(lmtest)) {install.packages("lmtest"); require(lmtest)}
dir <- setwd("/Users/Julian/Dropbox (alvarezlab)/Research-DeFreitas/Projects/moralCapture/moralCapture_data_github/e1_illusory_wrongs/data_and_analysis/data_all_except_async")
files <- list.files(pattern=('*txt'))
myJSON <- lapply(files, function(x) fromJSON(file=x)) #join into one single JSON file
(data_baseline <- lapply(myJSON, function(myJSON) { as.data.frame(myJSON) }))
data_baseline <- (data_baseline <- do.call(rbind, data_baseline))
data_baseline <- data_baseline[data_baseline$trialStruct.cond == 4,]
data_baseline$trialStruct.cond <- 0
#exclusions
data_baseline <- subset(data_baseline,(data_baseline$trialStruct.comprehension == "E"))
data_baseline <- subset(data_baseline,(data_baseline$trialStruct.displayTime < 4225 & data_baseline$trialStruct.displayTime > 4175))
data_baseline <- subset(data_baseline,(data_baseline$trialStruct.whichCar_choice == 2))
dim(data_baseline) #91 (same as in E1, obviously)
dir <- setwd("/Users/Julian/Dropbox (alvarezlab)/Research-DeFreitas/Projects/moralCapture/moralCapture_data_github/e2a_context_duration/data_and_analysis/data")
files <- list.files(pattern=('*txt'))
myJSON <- lapply(files, function(x) fromJSON(file=x)) #join into one single JSON file
(data <- lapply(myJSON, function(myJSON) { as.data.frame(myJSON) }))
data <- (data <- do.call(rbind, data))
data <- data[,c(1:20,22)]
# num ss recruited
dim(data) #562
#data before which car exclusion question
data <- subset(data,(data$trialStruct.comprehension == "E"))
dim(data)
data <-subset(data,(data$trialStruct.displayTime < 4225 & data$trialStruct.displayTime > 4175))
dim(data) #510
562 - 510 #excluded
sex <- as.factor(data$trialStruct.sex)
table(sex)[1]/sum(table(sex))
sex <- as.factor(data$trialStruct.sex)
table(sex)[1]/sum(table(sex))
age <- as.numeric(levels(data$trialStruct.age))[data$trialStruct.age]
mean(age)
#data after which car exclusion question
data <- subset(data,(data$trialStruct.whichCar_choice == 2))
dim(data) #379
100 - (((510-379)/510)*100)
#bind data into single dataset
data <- rbind(data,data_baseline)
## assign variable names
cond <- as.factor(data$trialStruct.cond)
table(cond)
blame <- as.numeric(levels(data$trialStruct.blame_scaled))[data$trialStruct.blame_scaled]
blame_choice <- as.factor(data$trialStruct.blame_choice)
#baseline
baseline_mean <- mean(blame[cond == 0]); baseline_mean
baseline_sd <- sd(blame[cond==0]); baseline_sd
baseline_length <- length(blame[cond == 0]); baseline_length
baseline_sem <- baseline_sd/sqrt(baseline_length); baseline_sem
baseline_add_sem <- baseline_mean + baseline_sem
baseline_minus_sem <- baseline_mean - baseline_sem
alpha = .05;
blame_mat <- matrix(NA,4,6)
colnames(blame_mat) <- c('cond','condNumbers','mean','sd','n','sem')
condNumbers <- c(1200,500,100,50)
for (i in 1:4) {
blame_mat[i,] <- c(i,condNumbers[i],mean(blame[cond == i]),sd(blame[cond==i]), length(blame[cond == i]),0)
blame_mat[i,6] <- blame_mat[i,4]/sqrt(blame_mat[i,5])
}
blame.summary <- as.data.frame(blame_mat, stringsAsFactors=F)
condNames <- c('(1200)ms','500ms','100ms','50ms')
## line plot - scaled blame
condNums <- blame.summary$condNumbers
blameMeans <- blame.summary$mean
blameSems <- blame.summary$sem
plot(condNums,blameMeans,xaxt="n",yaxt="n",pch=16, ylim=c(1,9),xlim=c(0,1200), xlab="Context Duration",ylab="Mean Blame Judgment",main="E2 - Context Duration",col="black", cex=1.6)
axis(2,cex.axis=1.5)
axis(1,cex.axis=1.5)
abline(baseline_add_sem,0, lty=1)
abline(baseline_mean,0, lty=5)
abline(baseline_minus_sem,0, lty=1)
lines(blame.summary[,2],blame.summary[,3],col='firebrick1',lwd=3)
segments(condNums,blameMeans-blameSems,condNums,blameMeans+blameSems,lwd=2,col="light gray")
## bar plot - blame choice
blameTable <- matrix(NA,5)
blameTable[1] <- length(blame_choice[cond==1 & blame_choice==1])/length(blame_choice[cond==1]) #1200ms
blameTable[2] <- length(blame_choice[cond==2 & blame_choice==1])/length(blame_choice[cond==2]) #500ms
blameTable[3] <- length(blame_choice[cond==3 & blame_choice==1])/length(blame_choice[cond==3]) #100ms
blameTable[4] <- length(blame_choice[cond==4 & blame_choice==1])/length(blame_choice[cond==4]) #50ms
blameTable[5] <- length(blame_choice[cond==0 & blame_choice==1])/length(blame_choice[cond==0]) #no context
barplot(blameTable[1:4], beside=TRUE,ylim=c(0,1.0),
legend.text=TRUE, main="Proportion Blaming Driver of Red Car", cex.axis=1.0, cex.main = 1.5,names = condNames,ylab="Proportion")
abline(a= blameTable[5], b = 0)
dim(data) #379
dir <- setwd("/Users/Julian/Dropbox (alvarezlab)/Research-DeFreitas/Projects/moralCapture/moralCapture_data_github/e2a_context_duration/data_and_analysis/data")
files <- list.files(pattern=('*txt'))
myJSON <- lapply(files, function(x) fromJSON(file=x)) #join into one single JSON file
(data <- lapply(myJSON, function(myJSON) { as.data.frame(myJSON) }))
data <- (data <- do.call(rbind, data))
data <- data[,c(1:20,22)]
# num ss recruited
dim(data) #562
#data before which car exclusion question
data <- subset(data,(data$trialStruct.comprehension == "E"))
dim(data)
data <-subset(data,(data$trialStruct.displayTime < 4225 & data$trialStruct.displayTime > 4175))
dim(data) #510
562 - 510 #excluded
sex <- as.factor(data$trialStruct.sex)
table(sex)[1]/sum(table(sex))
age <- as.numeric(levels(data$trialStruct.age))[data$trialStruct.age]
mean(age)
#data after which car exclusion question
data <- subset(data,(data$trialStruct.whichCar_choice == 2))
dim(data) #470
sex <- as.factor(data$trialStruct.sex)
table(sex)[1]/sum(table(sex))
dir <- setwd("/Users/Julian/Dropbox (alvarezlab)/Research-DeFreitas/Projects/moralCapture/moralCapture_data_github/e2a_context_duration/data_and_analysis/data")
files <- list.files(pattern=('*txt'))
myJSON <- lapply(files, function(x) fromJSON(file=x)) #join into one single JSON file
(data <- lapply(myJSON, function(myJSON) { as.data.frame(myJSON) }))
data <- (data <- do.call(rbind, data))
data <- data[,c(1:20,22)]
# num ss recruited
dim(data) #562
#data before which car exclusion question
data <- subset(data,(data$trialStruct.comprehension == "E"))
dim(data)
data <-subset(data,(data$trialStruct.displayTime < 4225 & data$trialStruct.displayTime > 4175))
dim(data) #510
562 - 510 #52 excluded
sex <- as.factor(data$trialStruct.sex)
table(sex)[1]/sum(table(sex))
age <- as.numeric(levels(data$trialStruct.age))[data$trialStruct.age]
mean(age)
#data after which car exclusion question
data <- subset(data,(data$trialStruct.whichCar_choice == 2))
dim(data) #470
100 - (((510-379)/510)*100)
#bind data into single dataset
data <- rbind(data,data_baseline)
## assign variable names
cond <- as.factor(data$trialStruct.cond)
table(cond)
blame <- as.numeric(levels(data$trialStruct.blame_scaled))[data$trialStruct.blame_scaled]
blame_choice <- as.factor(data$trialStruct.blame_choice)
#baseline
baseline_mean <- mean(blame[cond == 0]); baseline_mean
baseline_sd <- sd(blame[cond==0]); baseline_sd
baseline_length <- length(blame[cond == 0]); baseline_length
baseline_sem <- baseline_sd/sqrt(baseline_length); baseline_sem
baseline_add_sem <- baseline_mean + baseline_sem
baseline_minus_sem <- baseline_mean - baseline_sem
alpha = .05;
blame_mat <- matrix(NA,4,6)
colnames(blame_mat) <- c('cond','condNumbers','mean','sd','n','sem')
condNumbers <- c(1200,500,100,50)
for (i in 1:4) {
blame_mat[i,] <- c(i,condNumbers[i],mean(blame[cond == i]),sd(blame[cond==i]), length(blame[cond == i]),0)
blame_mat[i,6] <- blame_mat[i,4]/sqrt(blame_mat[i,5])
}
blame.summary <- as.data.frame(blame_mat, stringsAsFactors=F)
condNames <- c('(1200)ms','500ms','100ms','50ms')
## line plot - scaled blame
condNums <- blame.summary$condNumbers
blameMeans <- blame.summary$mean
blameSems <- blame.summary$sem
plot(condNums,blameMeans,xaxt="n",yaxt="n",pch=16, ylim=c(1,9),xlim=c(0,1200), xlab="Context Duration",ylab="Mean Blame Judgment",main="E2 - Context Duration",col="black", cex=1.6)
axis(2,cex.axis=1.5)
axis(1,cex.axis=1.5)
abline(baseline_add_sem,0, lty=1)
abline(baseline_mean,0, lty=5)
abline(baseline_minus_sem,0, lty=1)
lines(blame.summary[,2],blame.summary[,3],col='firebrick1',lwd=3)
segments(condNums,blameMeans-blameSems,condNums,blameMeans+blameSems,lwd=2,col="light gray")
## bar plot - blame choice
blameTable <- matrix(NA,5)
blameTable[1] <- length(blame_choice[cond==1 & blame_choice==1])/length(blame_choice[cond==1]) #1200ms
blameTable[2] <- length(blame_choice[cond==2 & blame_choice==1])/length(blame_choice[cond==2]) #500ms
blameTable[3] <- length(blame_choice[cond==3 & blame_choice==1])/length(blame_choice[cond==3]) #100ms
blameTable[4] <- length(blame_choice[cond==4 & blame_choice==1])/length(blame_choice[cond==4]) #50ms
blameTable[5] <- length(blame_choice[cond==0 & blame_choice==1])/length(blame_choice[cond==0]) #no context
barplot(blameTable[1:4], beside=TRUE,ylim=c(0,1.0),
legend.text=TRUE, main="Proportion Blaming Driver of Red Car", cex.axis=1.0, cex.main = 1.5,names = condNames,ylab="Proportion")
abline(a= blameTable[5], b = 0)
blame_mat
## anova of blame scaled for all conditions except baseline from e1
model <- aov(blame[cond!=0] ~ cond[cond!=0])
summary(model)
etaSquared(model)
# means and sd
blame_mat
length(cond[cond==0])
# 1200ms v 500ms
t.test(blame[cond==1 | cond==2] ~ cond[cond==1 | cond==2], var.equal=TRUE, paired=FALSE)
## anova of blame scaled for all conditions except baseline from e1
model <- aov(blame[cond!=0] ~ cond[cond!=0])
summary(model)
etaSquared(model)
# means and sd
blame_mat
length(cond[cond==0])
# 1200ms v 500ms
t.test(blame[cond==1 | cond==2] ~ cond[cond==1 | cond==2], var.equal=TRUE, paired=FALSE)
# 1200ms v 500ms
t.test(blame[cond==1 | cond==2] ~ cond[cond==1 | cond==2], var.equal=TRUE, paired=FALSE)
tes(0.88693,108,97) #0.12
# 1200ms v 100ms
t.test(blame[cond==1 | cond==3] ~ cond[cond==1 | cond==3], var.equal=TRUE, paired=FALSE)
tes(3.1753,108,92) #0.45
# 1200ms v 500ms
t.test(blame[cond==1 | cond==2] ~ cond[cond==1 | cond==2], var.equal=TRUE, paired=FALSE)
# means and sd
blame_mat
# 1200ms v 500ms
t.test(blame[cond==1 | cond==2] ~ cond[cond==1 | cond==2], var.equal=TRUE, paired=FALSE)
tes(0.88693,108,97) #0.12
# 1200ms v 500ms
t.test(blame[cond==1 | cond==2] ~ cond[cond==1 | cond==2], var.equal=TRUE, paired=FALSE)
tes(0.88693,108,97) #0.12
# 1200ms v 500ms
t.test(blame[cond==1 | cond==2] ~ cond[cond==1 | cond==2], var.equal=TRUE, paired=FALSE)
tes(0.88693,108,97) #0.12
# 1200ms v 100ms
t.test(blame[cond==1 | cond==3] ~ cond[cond==1 | cond==3], var.equal=TRUE, paired=FALSE)
# 1200ms v 100ms
t.test(blame[cond==1 | cond==3] ~ cond[cond==1 | cond==3], var.equal=TRUE, paired=FALSE)
tes(3.1753,108,92) #0.45
# 1200ms v 50ms
t.test(blame[cond==1 | cond==4] ~ cond[cond==1 | cond==4], var.equal=TRUE, paired=FALSE)
tes(5.45,108,82) #0.80
#no context vs. 1200ms
t.test(blame[cond==0 | cond==1] ~ cond[cond==0 | cond==1], var.equal=TRUE, paired=FALSE)
# means and sd
blame_mat
length(cond[cond==0])
##---- no context v other conds
length(cond[cond==0]) #length of no context condition
#no context vs. 1200ms
t.test(blame[cond==0 | cond==1] ~ cond[cond==0 | cond==1], var.equal=TRUE, paired=FALSE)
tes(-3.3927,91,108) #0.48
#no context vs. 500ms
t.test(blame[cond==0 | cond==2] ~ cond[cond==0 | cond==2], var.equal=TRUE, paired=FALSE)
#no context vs. 1200ms
t.test(blame[cond==0 | cond==1] ~ cond[cond==0 | cond==1], var.equal=TRUE, paired=FALSE)
tes(-3.3927,91,108) #0.48
#no context vs. 500ms
t.test(blame[cond==0 | cond==2] ~ cond[cond==0 | cond==2], var.equal=TRUE, paired=FALSE)
tes(-2.5572,91,97) #0.37
#no context vs. 100ms
t.test(blame[cond==0 | cond==3] ~ cond[cond==0 | cond==3], var.equal=TRUE, paired=FALSE)
tes(-0.38555,91,92)
#no context vs. 50ms
t.test(blame[cond==0 | cond==4] ~ cond[cond==0 | cond==4], var.equal=TRUE, paired=FALSE)
tes(1.7136,91,82)
blameChoiceTable <- table(blame_choice,cond); blameChoiceTable
blameTable
blameTable
# means and sd
blame_mat
blameChoiceTable <- table(blame_choice,cond); blameChoiceTable
blameTable
blameChoiceTable <- table(blame_choice,cond); blameChoiceTable
blameTable
# 1200ms v 500ms
length(cond[cond == 1 | cond == 2])
chisq.test(cond[cond == 1 | cond == 2], blame_choice[cond== 1 | cond == 2])
chisq.test(blameChoiceTable[,2:3])
cramersV(blameChoiceTable[,2:3])
blameTable
blameChoiceTable <- table(blame_choice,cond); blameChoiceTable
# 1200ms v 500ms
length(cond[cond == 1 | cond == 2])
chisq.test(cond[cond == 1 | cond == 2], blame_choice[cond== 1 | cond == 2])
cramersV(blameChoiceTable[,2:3])
# 1200ms v 100ms
length(cond[cond == 1 | cond == 3])
chisq.test(cond[cond == 1 | cond == 3], blame_choice[cond== 1 | cond == 3])
chisq.test(blameChoiceTable[,c(2,4)])
cramersV(blameChoiceTable[,c(2,4)])
# 1200ms v 50ms
length(cond[cond == 1 | cond == 4])
chisq.test(cond[cond == 1 | cond == 4], blame_choice[cond== 1 | cond == 4])
chisq.test(blameChoiceTable[,c(2,5)])
cramersV(blameChoiceTable[,c(2,5)])
#no context v 1200ms
length(cond[cond == 0 | cond == 1])
chisq.test(cond[cond == 0 | cond == 1], blame_choice[cond== 0 | cond == 1])
chisq.test(blameChoiceTable[,1:2])
cramersV(blameChoiceTable[,1:2])
#no context v 500ms
length(cond[cond == 0 | cond == 2])
chisq.test(cond[cond == 0 | cond == 2], blame_choice[cond== 0 | cond == 2])
chisq.test(blameChoiceTable[,c(1,3)])
cramersV(blameChoiceTable[,c(1,3)])
#no context v 100ms
length(cond[cond == 0 | cond == 3])
chisq.test(cond[cond == 0 | cond == 3], blame_choice[cond == 0 | cond == 3])
chisq.test(blameChoiceTable[,c(1,4)])
cramersV(blameChoiceTable[,c(1,4)])
#no context v 50ms
length(cond[cond == 0 | cond == 4])
chisq.test(cond[cond == 0 | cond == 4], blame_choice[cond== 0 | cond == 4])
chisq.test(blameChoiceTable[,c(1,5)])
cramersV(blameChoiceTable[,c(1,5)])
## clear workspace
rm(list = ls())
## necessary libraries
if (!require(rjson)) {install.packages("rjson"); require(rjson)}
if (!require(jsonlite)) {install.packages("jsonlite"); require(jsonlite)}
if (!require(ggplot2)) {install.packages("ggplot2"); require(ggplot2)}
if (!require(ltm)) {install.packages("ltm"); require(ltm)}
if (!require(heplots)) {install.packages("heplots"); require(heplots)}
if (!require(lmtest)) {install.packages("lmtest"); require(lmtest)}
dir <- setwd("/Users/Julian/Dropbox (alvarezlab)/Research-DeFreitas/Projects/moralCapture/moralCapture_data_github/e2b_temporal_asynchrony/data_and_analysis/data")
files <- list.files(pattern=('*txt'))
myJSON <- lapply(files, function(x) fromJSON(file=x)) #join into one single JSON file
(data_baseline <- lapply(myJSON, function(myJSON) { as.data.frame(myJSON) }))
function (txt, simplifyVector = TRUE, simplifyDataFrame = simplifyVector,
simplifyMatrix = simplifyVector, flatten = FALSE, ...)
## clear workspace
rm(list = ls())
## necessary libraries
if (!require(rjson)) {install.packages("rjson"); require(rjson)}
if (!require(jsonlite)) {install.packages("jsonlite"); require(jsonlite)}
if (!require(ggplot2)) {install.packages("ggplot2"); require(ggplot2)}
if (!require(ltm)) {install.packages("ltm"); require(ltm)}
if (!require(heplots)) {install.packages("heplots"); require(heplots)}
if (!require(lmtest)) {install.packages("lmtest"); require(lmtest)}
dir <- setwd("/Users/Julian/Dropbox (alvarezlab)/Research-DeFreitas/Projects/moralCapture/moralCapture_data_github/e2b_temporal_asynchrony/data_and_analysis/data")
files <- list.files(pattern=('*txt'))
myJSON <- lapply(files, function(x) fromJSON(file=x)) #join into one single JSON file
(data_baseline <- lapply(myJSON, function(myJSON) { as.data.frame(myJSON) }))
data_baseline <- (data_baseline <- do.call(rbind, data_baseline))
data_baseline <- data_baseline[data_baseline$trialStruct.cond == 4,]
dir <- setwd("/Users/Julian/Dropbox (alvarezlab)/Research-DeFreitas/Projects/moralCapture/moralCapture_data_github/e2b_temporal_asynchrony/data_and_analysis/data")
files <- list.files(pattern=('*txt'))
myJSON <- lapply(files, function(x) fromJSON(file=x)) #join into one single JSON file
